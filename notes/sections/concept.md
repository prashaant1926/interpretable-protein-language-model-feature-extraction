

This research aims to validate and expand upon the InterPLM framework by implementing their feature extraction methodology on protein language models (PLMs) at scale. The study will focus on developing interpretable representations of protein sequences by analyzing the internal representations learned by state-of-the-art PLMs such as ESM-2 and ProtBERT.

The project will utilize the UniProt database as the primary source of protein sequences, specifically targeting the UniRef100 dataset to maximize sequence diversity and coverage. We will implement the feature extraction pipeline to identify and label biologically meaningful features, including secondary structure elements, functional domains, and evolutionary conservation patterns.

A key innovation will be the development of automated labeling mechanisms that can associate extracted features with known biological properties, making the interpretations more accessible to biologists and protein scientists. This work will also explore the relationship between model architecture and feature interpretability, potentially leading to insights for designing more transparent PLMs.

